{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-XBvWmeT4VR",
        "outputId": "58cd91f4-da66-4004-9c81-075bee637fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju1SppnHUTU8"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "from pyspark.sql.functions import col, lower, regexp_replace, trim\n",
        "import os, re\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.pipeline import PipelineModel\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLGm8js-Un5x"
      },
      "outputs": [],
      "source": [
        "class Model_Inference:\n",
        "    def __init__(self):\n",
        "        self.pipeline_path = '/content/nb_pipeline'\n",
        "        self.nb_pipeline = self.load_pipeline()\n",
        "\n",
        "    def load_pipeline(self):\n",
        "        return PipelineModel.load(self.pipeline_path)\n",
        "\n",
        "    def predict(self, df):\n",
        "        df = (\n",
        "            df.withColumn(\"text_clean\", lower(col(\"texts\")))\n",
        "                  .withColumn(\"text_clean\", regexp_replace(col(\"text_clean\"), r\"https?://\\S+\", \"\"))\n",
        "                  .withColumn(\"text_clean\", regexp_replace(col(\"text_clean\"), r\"[^\\p{L}\\p{N}\\s]+\", \" \"))\n",
        "                  .withColumn(\"text_clean\", trim(regexp_replace(col(\"text_clean\"), r\"\\s+\", \" \")))\n",
        "        )\n",
        "        pred_new = self.nb_pipeline.transform(df)\n",
        "\n",
        "        return pred_new\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdECAV_cmin3"
      },
      "outputs": [],
      "source": [
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"Colab_Spark_TextML\")\n",
        "    .master(\"local[*]\")                # Dùng toàn bộ CPU có sẵn\n",
        "    .config(\"spark.driver.memory\", \"8g\")         # 8 GB cho driver (vừa đủ, tránh OOM)\n",
        "    .config(\"spark.executor.memory\", \"2g\")       # 2 GB cho executor (vì local mode, chỉ 1 executor)\n",
        "    .config(\"spark.driver.maxResultSize\", \"2g\")  # Giới hạn kết quả trả về driver\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"8\") # Giảm số shuffle partitions để đỡ overhead\n",
        "    .config(\"spark.default.parallelism\", \"8\")    # Giới hạn song song ở mức hợp lý\n",
        "    .getOrCreate()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuCTLg-jiK_l"
      },
      "outputs": [],
      "source": [
        "inference = Model_Inference()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgcG0RzunK8A",
        "outputId": "c6b277b5-d277-44d1-8b8c-17e145fc10b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_path = \"/content/data.csv\"\n",
        "n_rows = 500_000\n",
        "cols_needed = [\"texts\", \"labels\"]\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    header = f.readline()  # đọc header\n",
        "    tail_lines = deque(f, maxlen=n_rows)\n",
        "\n",
        "# Gộp lại thành chuỗi CSV\n",
        "data_str = header + \"\".join(tail_lines)\n",
        "\n",
        "# Đưa vào pandas rồi chuyển sang Spark\n",
        "df_tail_pd = pd.read_csv(StringIO(data_str), usecols=cols_needed)\n",
        "df_tail = spark.createDataFrame(df_tail_pd).repartition(8)\n",
        "df_tail.rdd.getNumPartitions()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF80DYqQrPwV"
      },
      "outputs": [],
      "source": [
        "df_pred = inference.predict(df_tail)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0xvpuqeYDFk",
        "outputId": "932d6cc6-23ee-4647-9100-a88d5ef8d1a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+\n",
            "|               texts|labels|          text_clean|              tokens|     tokens_filtered|         rawFeatures|            features|       rawPrediction|         probability|prediction_nb|\n",
            "+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+\n",
            "|tiến sĩ mà để nợ ...|     0|tiến sĩ mà để nợ ...|[ti, n, s, m, n, ...|[ti, n, m, n, c, ...|(262144,[1303,141...|(262144,[1303,141...|[-249.18945028910...|[0.68728653424899...|          0.0|\n",
            "|em nạp bằng mom...|     0|em na p bă ng mom...|[em, na, p, b, ng...|[em, na, p, b, ng...|(262144,[3386,141...|(262144,[3386,141...|[-813.63414883714...|[0.99999999979572...|          0.0|\n",
            "|Thì đúng mà, crus...|     0|thì đúng mà crush...|[th, ng, m, crush...|[th, ng, m, crush...|(262144,[1303,368...|(262144,[1303,368...|[-678.17950887461...|[1.0,2.0298110248...|          0.0|\n",
            "|Bên kia thấy đi đ...|     0|bên kia thấy đi đ...|[b, n, kia, th, y...|[b, n, kia, th, y...|(262144,[14208,28...|(262144,[14208,28...|[-423.49355375524...|[0.05310610547852...|          1.0|\n",
            "|           Là cả hai|     0|           là cả hai|         [l, c, hai]|         [l, c, hai]|(262144,[1303,749...|(262144,[1303,749...|[-40.418195930973...|[0.94742907992032...|          0.0|\n",
            "+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pred.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaUaJgOFrf6L",
        "outputId": "d17ea54d-2b1f-4460-a746-c8903e040a3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Area Under ROC: 0.8479859149746666\n",
            "Area Under PR: 0.3154070809367029\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='labels', rawPredictionCol='probability')\n",
        "print('Area Under ROC:', evaluator.evaluate(df_pred))\n",
        "print('Area Under PR:', evaluator.evaluate(df_pred, {evaluator.metricName: \"areaUnderPR\"}))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIngqQw2a4-C",
        "outputId": "785b1323-ea0e-4556-a0ec-3f77c40ff3d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.678964\n",
            "F1: 0.7664033381436142\n"
          ]
        }
      ],
      "source": [
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol='labels', predictionCol='prediction_nb')\n",
        "print('Accuracy:', multi_evaluator.evaluate(df_pred, {multi_evaluator.metricName: \"accuracy\"}))\n",
        "print('F1:', multi_evaluator.evaluate(df_pred, {multi_evaluator.metricName: \"f1\"}))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
